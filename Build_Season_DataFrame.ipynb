{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Master Data Frame For One Seasons Worth Of Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import difflib\n",
    "import math\n",
    "import re\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the path which the data is stored\n",
    "<b><u> Note: </u></b> The path structure must be as follows:\n",
    "- File_path_to_data_directory\n",
    "    - MatchUp\n",
    "        - 2015\n",
    "        - 2016\n",
    "        - 2017\n",
    "        - 2018\n",
    "        - 2019\n",
    "    - Box_Office\n",
    "        - 2015_Box_Office_Individual_Players\n",
    "        - 2016_Box_Office_Individual_Players\n",
    "        - 2017_Box_Office_Individual_Players\n",
    "        - 2018_Box_Office_Individual_Players\n",
    "        - 2019_Box_Office_Individual_Players\n",
    "    - Master_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the following information and run all cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "file_path_to_data_directory = os.path.join(os.sep,'Users', 'carlylagrotta', 'Dropbox', 'Columbia','Fall_2020_Semester', 'Data_Science','Data_Science_For_Mechanical_Systems')\n",
    "file_path_to_write_master_csv_to = os.path.join(os.sep,'Users','carlylagrotta','Desktop','master_df_'+str(year)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check if a game day matchup file exists for a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_game_day_matchup_file_exists(gameDate,file_path=file_path_to_data_directory):\n",
    "    file_name = os.path.join('MatchUp',str(gameDate.year),'PitcherBatterMatchUp_'+str(gameDate.date())+'.csv')\n",
    "    \n",
    "    full_path = os.path.join(file_path,file_name)\n",
    "\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse a game day matchup file (if it exists) and return a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_day_expected_matchup(gameDate,file_path=file_path_to_data_directory):    \n",
    "    file_name = os.path.join('MatchUp', str(gameDate.year), 'PitcherBatterMatchUp_'+ str(gameDate.date())+'.csv')\n",
    "    full_path = os.path.join(file_path,file_name)\n",
    "    df = pd.read_csv(full_path)\n",
    "    df.drop(['Unnamed: 0','TeamMatchUp'],axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that when passed a single name and a list of names can return a list of the most similar names for the list as compared to the single name it was passed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_name_match(batter_name,path):\n",
    "    directory_contents = [name for name in os.listdir(path)]\n",
    "    stripped_csv_name = [name[:-4].replace('_',' ') for name in directory_contents ]\n",
    "    close =difflib.get_close_matches(batter_name,stripped_csv_name)\n",
    "    return close\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that helps determine if the two names it was paseed are the same but potentially could have just been represented differently in two different datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_name(closest_name,name):\n",
    "    nickname_dict = {'Christopher':'Chris',\n",
    "                 'Chris':'Christopher',\n",
    "                 'Nicholas':'Nick',\n",
    "                  'Nick': 'Nicholas',\n",
    "                 'Matthew':'Matt',\n",
    "                'Matt':'Matthew',\n",
    "                'Gio':'Giovanny',\n",
    "                'Giovanny':'Gio',\n",
    "                'Nori':'Norichika',\n",
    "                 'Norichika':'Nori',\n",
    "                'Jakob':'Jake',\n",
    "                    'Jake':'Jakob',\n",
    "                    'Phil':'Phillip',\n",
    "                    'Phillip':'Phil',\n",
    "                    'Rafael':'Raffy',\n",
    "                    'Raffy':'Rafael',\n",
    "                    'Jonathon':'Jon',\n",
    "                     'Jon':'Jonathon',\n",
    "                    'Steven':'Steve',\n",
    "                    'Steve':'Steven',\n",
    "                     'Stevie':'Steven',\n",
    "                     'Steven':'Stevie',\n",
    "                    'Tommy':'Thomas',\n",
    "                     'Thomas':'Tommy',\n",
    "                     'Daniel':'Danny',\n",
    "                     'Danny':'Daniel',\n",
    "                     'Rey':'Reymond',\n",
    "                     'Reymond':'Rey',\n",
    "                     'Michael':'Mike',\n",
    "                     'Mike':'Michael',\n",
    "                     'Nathan':'Nate',\n",
    "                     'Nate':'Nathan',\n",
    "                     'Reymond':'Rey',\n",
    "                     'Rey':'Reymond',\n",
    "                     'ByungHo':'Byung Ho',\n",
    "                     'Byung Ho':'ByungHo',\n",
    "                     'Yuli':'Yulieski',\n",
    "                     'Yulieski':'Yuli',\n",
    "                     'David':'Dave',\n",
    "                     'Dave':'David',\n",
    "                     'Stevie':'Steven',\n",
    "                     'Steven':'Stevie',\n",
    "                     'Pete':'Peter',\n",
    "                     'Peter':'Pete'\n",
    "                    }\n",
    "    \n",
    "    \n",
    "    #check for JR\n",
    "    closest_name_original = copy.deepcopy(closest_name)\n",
    "    closest_name = closest_name.replace('.','') \n",
    "    name = name.replace('.','')      \n",
    "    \n",
    "    \n",
    "    closest_name =  re.sub(r'\\bJr\\b','',closest_name) \n",
    "    name = re.sub(r'\\bJr\\b','',name)\n",
    "    \n",
    "    closest_name = closest_name.replace('-',' ')\n",
    "    name = name.replace('-',' ')\n",
    "    \n",
    "    closest_name_no_apst_without_space = closest_name.replace(\"'\",'')\n",
    "    name_no_apst_without_space = name.replace(\"'\",'') \n",
    "    \n",
    "    closest_name_no_apst_with_space = closest_name.replace(\"'\",' ')\n",
    "    name_no_apst_with_space = name.replace(\"'\",' ')     \n",
    "    \n",
    "    \n",
    "\n",
    "    closest_arr = closest_name_no_apst_with_space.strip().split(' ')\n",
    "    name_arr = name_no_apst_with_space.strip().split(' ')\n",
    "    \n",
    "    if closest_arr[-1].strip() == name_arr[-1].strip() and closest_arr[0].strip() == name_arr[0].strip():\n",
    "        return (True,closest_name_original)\n",
    "    \n",
    "    closest_arr_without_space = closest_name_no_apst_without_space.strip().split(' ')\n",
    "    name_arr_without_space = name_no_apst_without_space.strip().split(' ')\n",
    "    \n",
    "    if closest_arr_without_space[-1].strip() == name_arr_without_space[-1].strip() and closest_arr_without_space[0].strip() == name_arr_without_space[0].strip():\n",
    "        return (True,closest_name_original)\n",
    "\n",
    "    \n",
    "    if closest_arr[-1].strip() == name_arr[-1].strip() and closest_arr[0].strip()[0] == name_arr[0].strip()[0]:\n",
    "        \n",
    "        if name_arr[0] in nickname_dict.keys():\n",
    "            name_in_file = nickname_dict[name_arr[0]]\n",
    "            if name_in_file +' '+\" \".join(closest_arr[1:]) == \" \".join(closest_arr):\n",
    "            #print(name_in_file +' '+\" \".join(closest_arr[1:]))\n",
    "\n",
    "                return (True,name_in_file +' '+\" \".join(closest_arr[1:]))\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        #return (closest_arr,name_arr)\n",
    "\n",
    "    elif closest_arr_without_space[-1].strip() == name_arr_without_space[-1].strip() and closest_arr_without_space[0].strip()[0] == name_arr_without_space[0].strip()[0]:\n",
    "        \n",
    "        if name_arr_without_space[0] in nickname_dict.keys():\n",
    "            name_in_file = nickname_dict[name_arr_without_space[0]]\n",
    "            if name_in_file +' '+\" \".join(name_arr_without_space[1:]) == \" \".join(closest_arr_without_space):\n",
    "            #print(name_in_file +' '+\" \".join(name_arr_without_space[1:]))\n",
    "\n",
    "                return (True,name_in_file +' '+\" \".join(name_arr_without_space[1:]))   \n",
    "        else:\n",
    "            return False\n",
    "        #return (closest_arr_without_space,name_arr_without_space)\n",
    "\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check if a box office file exists for a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_box_office_file_exists(batter_name,gameDate,file_path=file_path_to_data_directory):\n",
    "    #file_name = 'Box_Office/' + str(gameDate.year) + '_Box_Office_Individual_Players/'+batter_name.replace(' ','_')+'.csv'    \n",
    "    file_name = os.path.join('Box_Office',str(gameDate.year)+'_Box_Office_Individual_Players',batter_name.replace(' ','_')+'.csv')\n",
    "    full_path = os.path.join(file_path,file_name)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        closest_guess = get_closest_name_match(batter_name,os.path.join(file_path,'Box_Office',str(gameDate.year)+ '_Box_Office_Individual_Players',os.sep))\n",
    "        #closest_guess= get_closest_name_match(batter_name,file_path+'Box_Office/' + str(gameDate.year) + '_Box_Office_Individual_Players/')\n",
    "        \n",
    "        if closest_guess == []:\n",
    "            return False\n",
    "        else:  \n",
    "            return cleaning_name(closest_guess[0],batter_name)        \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse a box office file for a specific player (if it exists) and return a Pandas DataFrame for a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_file_for_box_office_on_a_date(batter_name,gameDate,file_path=file_path_to_data_directory):\n",
    "    #file_name = 'Box_Office/' + str(gameDate.year) + '_Box_Office_Individual_Players/'+batter_name.replace(' ','_')+'.csv'\n",
    "    file_name = os.path.join('Box_Office',str(gameDate.year)+'_Box_Office_Individual_Players',batter_name.replace(' ','_')+'.csv')\n",
    "    \n",
    "    #full_path = file_path + file_name\n",
    "    full_path = os.path.join(file_path,file_name)\n",
    "    df = pd.read_csv(full_path)\n",
    "    temp_df =  df[df['Date'].str.contains(str(gameDate.date()))]\n",
    "    temp_df = temp_df.drop(['Unnamed: 0', 'Batting','R','RBI', 'BB', 'SO',\n",
    "       'OBP', 'SLG', 'OPS', 'Pit', 'Str', 'WPA', 'aLI', 'WPA+', 'WPA-', 'RE24',\n",
    "       'PO', 'A', 'Details', 'Team', 'Date'],axis=1)\n",
    "    if not temp_df.empty:\n",
    "        temp_df = temp_df.iloc[0]\n",
    "    return temp_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that finds the age and years of experiance of a specific player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_and_birthday(batter_name,file_path = file_path_to_data_directory):\n",
    "    bday_path = os.path.join('Birthday','master_birthday_list.csv')\n",
    "    df_birthday = pd.read_csv(os.path.join(file_path,bday_path))\n",
    "    temp_df =  df_birthday[df_birthday['Name'].str.contains(str(batter_name))]\n",
    "    if not temp_df.empty:\n",
    "        return temp_df\n",
    "    else:       \n",
    "        close =difflib.get_close_matches(batter_name,df_birthday['Name'].to_list())\n",
    "        if close != []:\n",
    "            cleaned_result = cleaning_name(close[0],batter_name)\n",
    "            if type(cleaned_result) == tuple and cleaned_result[0]==True:\n",
    "                closest_name_original = cleaned_result[1]    \n",
    "                temp_df =  df_birthday[df_birthday['Name'].str.contains(str(closest_name_original))]\n",
    "                if not temp_df.empty:\n",
    "                    return temp_df\n",
    "                else:\n",
    "                    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to determine the length of the longest list inside a nested list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_of_longest_list(lists):\n",
    "    longest = len(max(lists, key=len))\n",
    "    return longest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make all the sub lists inside a nested list the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_lists_same_length(longest_list,master_list):\n",
    "    for i,sublist in enumerate(master_list):\n",
    "        if len(sublist)< longest_list:\n",
    "            master_list[i] = sublist*longest_list \n",
    "    return master_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check the length of all sub lists inside a master list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_len_of_master_list(master_list):\n",
    "    lengths = []\n",
    "    for lst in master_list:\n",
    "        lengths.append(len(lst))\n",
    "    \n",
    "    return max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build a temporary data frame for a specific day and player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulild_temp_df(master_list_same_length):\n",
    "    kys = ['Batter',\n",
    "    'Batter_Handedness',\n",
    "    'Pitcher_Handedness',\n",
    "    'Stadium',\n",
    "    'Batter_Home',\n",
    "    'Date',\n",
    "    'Position_In_Lineup',\n",
    "    'Pitcher',\n",
    "    'Batting_Average',\n",
    "    'Number_Of_Plate_Appearances',\n",
    "    'Batter_Age',\n",
    "    'Batter_Exp',\n",
    "    'Pitcher_Age',\n",
    "    'Pitcher_Exp',\n",
    "     'Number_Of_Hits']\n",
    "    temp_dict = dict(zip(kys,master_list_same_length))\n",
    "    temp_df = pd.DataFrame(temp_dict)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of dates based on the specific season of play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2019:\n",
    "    dates = pd.date_range(start=\"2019-04-13\",end=\"2019-10-20\")\n",
    "elif year == 2018:\n",
    "    dates = pd.date_range(start=\"2018-03-30\",end=\"2018-10-28\")\n",
    "elif year ==2017:\n",
    "    dates = pd.date_range(start=\"2017-04-02\",end=\"2017-11-01\")\n",
    "elif year ==2016:\n",
    "    dates = pd.date_range(start=\"2016-04-03\",end=\"2016-11-02\")\n",
    "elif year ==2015:\n",
    "    dates = pd.date_range(start=\"2015-04-04\",end=\"2015-11-01\")\n",
    "else:\n",
    "    dates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a data frame for one season worth of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 00:00:00\n",
      "2019-04-14 00:00:00\n",
      "2019-04-15 00:00:00\n",
      "2019-04-16 00:00:00\n",
      "2019-04-17 00:00:00\n",
      "2019-04-18 00:00:00\n",
      "2019-04-19 00:00:00\n",
      "2019-04-20 00:00:00\n",
      "2019-04-21 00:00:00\n",
      "2019-04-22 00:00:00\n",
      "2019-04-23 00:00:00\n",
      "2019-04-24 00:00:00\n",
      "2019-04-25 00:00:00\n",
      "2019-04-26 00:00:00\n",
      "2019-04-27 00:00:00\n",
      "2019-04-28 00:00:00\n",
      "2019-04-29 00:00:00\n",
      "2019-04-30 00:00:00\n",
      "2019-05-01 00:00:00\n",
      "2019-05-02 00:00:00\n",
      "2019-05-03 00:00:00\n",
      "2019-05-04 00:00:00\n",
      "2019-05-05 00:00:00\n",
      "2019-05-06 00:00:00\n",
      "2019-05-07 00:00:00\n",
      "2019-05-08 00:00:00\n",
      "2019-05-09 00:00:00\n",
      "2019-05-10 00:00:00\n",
      "2019-05-11 00:00:00\n",
      "2019-05-12 00:00:00\n",
      "2019-05-13 00:00:00\n",
      "2019-05-14 00:00:00\n",
      "2019-05-15 00:00:00\n",
      "2019-05-16 00:00:00\n",
      "2019-05-17 00:00:00\n",
      "2019-05-18 00:00:00\n",
      "2019-05-19 00:00:00\n",
      "2019-05-20 00:00:00\n",
      "2019-05-21 00:00:00\n",
      "2019-05-22 00:00:00\n",
      "2019-05-23 00:00:00\n",
      "2019-05-24 00:00:00\n",
      "2019-05-25 00:00:00\n",
      "2019-05-26 00:00:00\n",
      "2019-05-27 00:00:00\n",
      "2019-05-28 00:00:00\n",
      "2019-05-29 00:00:00\n",
      "2019-05-30 00:00:00\n",
      "2019-05-31 00:00:00\n",
      "2019-06-01 00:00:00\n",
      "2019-06-02 00:00:00\n",
      "2019-06-03 00:00:00\n",
      "2019-06-04 00:00:00\n",
      "2019-06-05 00:00:00\n",
      "2019-06-06 00:00:00\n",
      "2019-06-07 00:00:00\n",
      "2019-06-08 00:00:00\n",
      "2019-06-09 00:00:00\n",
      "2019-06-10 00:00:00\n",
      "2019-06-11 00:00:00\n",
      "2019-06-12 00:00:00\n",
      "2019-06-13 00:00:00\n",
      "2019-06-14 00:00:00\n",
      "2019-06-15 00:00:00\n",
      "2019-06-16 00:00:00\n",
      "2019-06-17 00:00:00\n",
      "2019-06-18 00:00:00\n",
      "2019-06-19 00:00:00\n",
      "2019-06-20 00:00:00\n",
      "2019-06-21 00:00:00\n",
      "2019-06-22 00:00:00\n",
      "2019-06-23 00:00:00\n",
      "2019-06-24 00:00:00\n",
      "2019-06-25 00:00:00\n",
      "2019-06-26 00:00:00\n",
      "2019-06-27 00:00:00\n",
      "2019-06-28 00:00:00\n",
      "2019-06-29 00:00:00\n",
      "2019-06-30 00:00:00\n",
      "2019-07-01 00:00:00\n",
      "2019-07-02 00:00:00\n",
      "2019-07-03 00:00:00\n",
      "2019-07-04 00:00:00\n",
      "2019-07-05 00:00:00\n",
      "2019-07-06 00:00:00\n",
      "2019-07-07 00:00:00\n",
      "2019-07-08 00:00:00\n",
      "2019-07-09 00:00:00\n",
      "2019-07-10 00:00:00\n",
      "2019-07-11 00:00:00\n",
      "2019-07-12 00:00:00\n",
      "2019-07-13 00:00:00\n",
      "2019-07-14 00:00:00\n",
      "2019-07-15 00:00:00\n",
      "2019-07-16 00:00:00\n",
      "2019-07-17 00:00:00\n",
      "2019-07-18 00:00:00\n",
      "2019-07-19 00:00:00\n",
      "2019-07-20 00:00:00\n",
      "2019-07-21 00:00:00\n",
      "2019-07-22 00:00:00\n",
      "2019-07-23 00:00:00\n",
      "2019-07-24 00:00:00\n",
      "2019-07-25 00:00:00\n",
      "2019-07-26 00:00:00\n",
      "2019-07-27 00:00:00\n",
      "2019-07-28 00:00:00\n",
      "2019-07-29 00:00:00\n",
      "2019-07-30 00:00:00\n",
      "2019-07-31 00:00:00\n",
      "2019-08-01 00:00:00\n",
      "2019-08-02 00:00:00\n",
      "2019-08-03 00:00:00\n",
      "2019-08-04 00:00:00\n",
      "2019-08-05 00:00:00\n",
      "2019-08-06 00:00:00\n",
      "2019-08-07 00:00:00\n",
      "2019-08-08 00:00:00\n",
      "2019-08-09 00:00:00\n",
      "2019-08-10 00:00:00\n",
      "2019-08-11 00:00:00\n",
      "2019-08-12 00:00:00\n",
      "2019-08-13 00:00:00\n",
      "2019-08-14 00:00:00\n",
      "2019-08-15 00:00:00\n",
      "2019-08-16 00:00:00\n",
      "2019-08-17 00:00:00\n",
      "2019-08-18 00:00:00\n",
      "2019-08-19 00:00:00\n",
      "2019-08-20 00:00:00\n",
      "2019-08-21 00:00:00\n",
      "2019-08-22 00:00:00\n",
      "2019-08-23 00:00:00\n",
      "2019-08-24 00:00:00\n",
      "2019-08-25 00:00:00\n",
      "2019-08-26 00:00:00\n",
      "2019-08-27 00:00:00\n",
      "2019-08-28 00:00:00\n",
      "2019-08-29 00:00:00\n",
      "2019-08-30 00:00:00\n",
      "2019-08-31 00:00:00\n",
      "2019-09-01 00:00:00\n",
      "2019-09-02 00:00:00\n",
      "2019-09-03 00:00:00\n",
      "2019-09-04 00:00:00\n",
      "2019-09-05 00:00:00\n",
      "2019-09-06 00:00:00\n",
      "2019-09-07 00:00:00\n",
      "2019-09-08 00:00:00\n",
      "2019-09-09 00:00:00\n",
      "2019-09-10 00:00:00\n",
      "2019-09-11 00:00:00\n",
      "2019-09-12 00:00:00\n",
      "2019-09-13 00:00:00\n",
      "2019-09-14 00:00:00\n",
      "2019-09-15 00:00:00\n",
      "2019-09-16 00:00:00\n",
      "2019-09-17 00:00:00\n",
      "2019-09-18 00:00:00\n",
      "2019-09-19 00:00:00\n",
      "2019-09-20 00:00:00\n",
      "2019-09-21 00:00:00\n",
      "2019-09-22 00:00:00\n",
      "2019-09-23 00:00:00\n",
      "2019-09-24 00:00:00\n",
      "2019-09-25 00:00:00\n",
      "2019-09-26 00:00:00\n",
      "2019-09-27 00:00:00\n",
      "2019-09-28 00:00:00\n",
      "2019-09-29 00:00:00\n",
      "2019-09-30 00:00:00\n",
      "2019-10-01 00:00:00\n",
      "2019-10-02 00:00:00\n",
      "2019-10-03 00:00:00\n",
      "2019-10-04 00:00:00\n",
      "2019-10-05 00:00:00\n",
      "2019-10-06 00:00:00\n",
      "2019-10-07 00:00:00\n",
      "2019-10-08 00:00:00\n",
      "2019-10-09 00:00:00\n",
      "2019-10-10 00:00:00\n",
      "2019-10-11 00:00:00\n",
      "2019-10-12 00:00:00\n",
      "2019-10-13 00:00:00\n",
      "2019-10-14 00:00:00\n",
      "2019-10-15 00:00:00\n",
      "2019-10-16 00:00:00\n",
      "2019-10-17 00:00:00\n",
      "2019-10-18 00:00:00\n",
      "2019-10-19 00:00:00\n",
      "2019-10-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "master_df =[]\n",
    "for counter,d in enumerate(dates):\n",
    "    print(d)\n",
    "    check_game_day_matchup_exists_file_result = check_if_game_day_matchup_file_exists(d)\n",
    "\n",
    "    if check_game_day_matchup_exists_file_result==True:\n",
    "        #for index, row in game_day_expected_matchup(game_day).iterrows():    \n",
    "        for index, row in game_day_expected_matchup(d).iterrows():\n",
    "            player = row['Batter']\n",
    "            player = player.strip()\n",
    "            \n",
    "            #getting data from matchup\n",
    "            Batter = [row['Batter']]\n",
    "            Pitcher = [row['PitcherFromTheOtherTeam']]\n",
    "            Batter_Handedness = [row['BatterHand']]\n",
    "            Pitcher_Handedness = [row['PitcherHand']]\n",
    "            Stadium = [row['Standium']]\n",
    "            Batter_Home = [row['Home/Away']]\n",
    "            Date = [row['Date']]\n",
    "            Position_In_Lineup = [row['LineUpPosition']]\n",
    "            \n",
    " #some of these could be longer than other             \n",
    "\n",
    "\n",
    "            result_box_file_exists = check_if_box_office_file_exists(player,d)\n",
    "            \n",
    "            \n",
    "            if result_box_file_exists==True and type(result_box_file_exists)!=tuple:\n",
    "                df_temp_box_office = get_csv_file_for_box_office_on_a_date(player,d)\n",
    "                if not df_temp_box_office.empty:            \n",
    "                    Batting_Average = [df_temp_box_office['BA']]\n",
    "                    Number_Of_Plate_Appearances = [df_temp_box_office['PA']]\n",
    "                    Number_Of_Hits = [df_temp_box_office['H']]\n",
    "                    \n",
    "                else:\n",
    "                    Batting_Average = [np.nan]\n",
    "                    Number_Of_Plate_Appearances = [np.nan]\n",
    "                    Number_Of_Hits = [np.nan]    \n",
    "            \n",
    "            \n",
    "            elif type(result_box_file_exists)==tuple and result_box_file_exists[0]==True:\n",
    "                corrected_batter_name_box_office = result_box_file_exists[1]\n",
    "                df_temp_box_office = get_csv_file_for_box_office_on_a_date(corrected_batter_name_box_office,d)\n",
    "                if not df_temp_box_office.empty:            \n",
    "                    Batting_Average = [df_temp_box_office['BA']]\n",
    "                    Number_Of_Plate_Appearances = [df_temp_box_office['PA']] \n",
    "                    Number_Of_Hits = [df_temp_box_office['H']]\n",
    "                \n",
    "                else:\n",
    "                    Batting_Average = [np.nan]\n",
    "                    Number_Of_Plate_Appearances = [np.nan]\n",
    "                    Number_Of_Hits = [np.nan]\n",
    "\n",
    "            \n",
    "            #elif result_box_file_exists==False and type(result_box_file_exists)!=tuple:\n",
    "            else:\n",
    "                Batting_Average = [np.nan]\n",
    "                Number_Of_Plate_Appearances = [np.nan]\n",
    "                Number_Of_Hits = [np.nan]\n",
    "\n",
    "                    \n",
    "                    \n",
    "            birthday_result_batter = get_age_and_birthday(player) \n",
    "            if isinstance(birthday_result_batter, pd.DataFrame):\n",
    "                Batter_Age = [datetime.now().year - int(birthday_result_batter['Born'])] \n",
    "                Batter_Exp = birthday_result_batter['Yrs'].to_list()\n",
    "            else:\n",
    "                #average age\n",
    "                Batter_Age = [30]\n",
    "                Batter_Exp = [3]\n",
    "            \n",
    "            Pitcher_Age = []\n",
    "            Pitcher_Exp=[]\n",
    "            if isinstance(Pitcher[0],str): \n",
    "\n",
    "                #and not math.isnan(Pitcher[0]):\n",
    "                for pitch in Pitcher: \n",
    "                    birthday_result_pitcher = get_age_and_birthday(pitch)        \n",
    "                    if isinstance(birthday_result_pitcher, pd.DataFrame):\n",
    "                        Pitcher_Age.append(datetime.now().year - int(birthday_result_pitcher['Born']) )\n",
    "                        Pitcher_Exp.append(int(birthday_result_pitcher['Yrs']))\n",
    "                    else:\n",
    "                        Pitcher_Age.append(30)  \n",
    "                        Pitcher_Exp.append(3)\n",
    "            else:\n",
    "                Pitcher_Age = [np.nan]\n",
    "                Pitcher_Exp=[np.nan]            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            #build temp df\n",
    "            #find the length of the longest list \n",
    "            master_list = [Batter,\n",
    "                           Batter_Handedness,\n",
    "                           Pitcher_Handedness,\n",
    "                           Stadium,\n",
    "                           Batter_Home,\n",
    "                           Date,\n",
    "                           Position_In_Lineup,\n",
    "                           Pitcher,\n",
    "                           Batting_Average,\n",
    "                           Number_Of_Plate_Appearances,\n",
    "                           Batter_Age,\n",
    "                           Batter_Exp,\n",
    "                           Pitcher_Age,\n",
    "                           Pitcher_Exp,\n",
    "                           Number_Of_Hits] \n",
    "            #maximum_length = checking_len_of_master_list(master_list)\n",
    "        #print(Result)\n",
    "            longest = length_of_longest_list(master_list)\n",
    "            master_list_equal_lengths = make_all_lists_same_length(longest,master_list)\n",
    "            temp_df = bulild_temp_df(master_list_equal_lengths)\n",
    "            master_df.append(temp_df)\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "    elif check_game_day_matchup_exists_file_result==False:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate temporary data frames into one big data frame, clean it and export it to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(master_df,ignore_index=True)\n",
    "df_cleaned = copy.deepcopy(df)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned.to_csv(file_path_to_write_master_csv_to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
